{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from matplotlib import pyplot as plt \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.raw_dir\n",
    "        self.processed_dir\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"CR_graph_rel.csv\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_0.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def process(self):\n",
    "        d = {\n",
    "            'мордвины': torch.tensor(0, dtype=torch.long),\n",
    "            'белорусы': torch.tensor(1, dtype=torch.long),\n",
    "            'украинцы': torch.tensor(2, dtype=torch.long),\n",
    "            'южные-русские': torch.tensor(3, dtype=torch.long),\n",
    "            'северные-русские': torch.tensor(4, dtype=torch.long)\n",
    "        }\n",
    "        oho = {\n",
    "            'мордвины': torch.tensor([1, 0, 0, 0, 0], dtype=torch.float),\n",
    "            'белорусы': torch.tensor([0, 1, 0, 0, 0], dtype=torch.float),\n",
    "            'украинцы': torch.tensor([0, 0, 1, 0, 0], dtype=torch.float),\n",
    "            'южные-русские': torch.tensor([0, 0, 0, 1, 0], dtype=torch.float),\n",
    "            'северные-русские': torch.tensor([0, 0, 0, 0, 1], dtype=torch.float)\n",
    "        }\n",
    "        \n",
    "        idx = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            edge_index = []\n",
    "            edge_attr = []\n",
    "            \n",
    "            y_labels = {}\n",
    "            oho_labels = {}\n",
    "            \n",
    "            dataset_csv = pd.read_csv(raw_path)\n",
    "            \n",
    "            for index, row in tqdm(dataset_csv.iterrows()):\n",
    "                node1 = row[\"node_id1\"]\n",
    "                node2 = row[\"node_id2\"]\n",
    "                label1 = row[\"label_id1\"]\n",
    "                label2 = row[\"label_id2\"]\n",
    "                ibd_sum = row[\"ibd_sum\"]\n",
    "\n",
    "                id1 = int(node1[5:])\n",
    "                id2 = int(node2[5:])\n",
    "\n",
    "                edge_index.append(torch.tensor([id1, id2], dtype=torch.long))\n",
    "                edge_attr.append(torch.tensor([ibd_sum], dtype=torch.float))\n",
    "\n",
    "                if id1 not in oho_labels:\n",
    "                    y_labels[id1] = d[label1]\n",
    "                    oho_labels[id1] = oho[label1]\n",
    "                if id2 not in oho_labels:\n",
    "                    y_labels[id2] = d[label2]\n",
    "                    oho_labels[id2] = oho[label2]\n",
    "            \n",
    "            y_labels = dict(sorted(y_labels.items()))\n",
    "            y = torch.stack(list(y_labels.values()))\n",
    "            \n",
    "            oho_labels = dict(sorted(oho_labels.items()))\n",
    "            x = torch.stack(list(oho_labels.values()))\n",
    "            edge_attr = torch.stack(edge_attr).contiguous()\n",
    "            edge_index = torch.stack(edge_index).t().contiguous()\n",
    "\n",
    "            data = Data(x=x ,edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyOwnDataset(root=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3767, 5], edge_index=[2, 67503], edge_attr=[67503, 1], y=[3767])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([154.9714,   5.4714,   4.9714,  53.1000,  38.2429])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([154.97142857,   5.47142857,   4.97142857,  53.1       ,\n",
    "         38.24285714])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {0: torch.tensor([0.60357202, 0.02130974, 0.01936238, 0.20681022, 0.14894564]),\n",
    " 1: torch.tensor([0.00200091, 0.49544179, 0.0547664 , 0.35631331, 0.09147759]),\n",
    " 2: torch.tensor([0.002216  , 0.06675369, 0.56663271, 0.29599465, 0.06840295]),\n",
    " 3: torch.tensor([0.00323319, 0.05932558, 0.04043269, 0.8123698 , 0.08463874]),\n",
    " 4: torch.tensor([0.01200443, 0.07851983, 0.04817019, 0.43633885, 0.4249667 ])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for element in data.x:\n",
    "    res.append(torch.concat((element, d[torch.argmax(element).item()]), dim=-1))\n",
    "\n",
    "res = torch.stack(res).contiguous()\n",
    "\n",
    "big_data = Data(x=res, edge_index=data.edge_index, edge_attr=data.edge_attr, y=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomNodeSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomNodeSplit(split='train_rest', num_splits=1,\n",
    "                                num_val=0.0, num_test=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data = transform(big_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(torch.nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight # weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        ce_loss = F.cross_entropy(input, target, reduction=self.reduction, weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(10, 10, add_self_loops=False, normalize=True)\n",
    "        #self.conv2 = GCNConv(5, 5, add_self_loops=False, normalize=True)\n",
    "        self.fc1 = Linear(10, 10)\n",
    "        self.fc2 = Linear(10, 10)\n",
    "        self.fc3 = Linear(10, 10)\n",
    "        self.fc4 = Linear(10, 5)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.conv1(x, edge_index, edge_weight)\n",
    "        h = h.relu()\n",
    "        #h = self.conv2(h, edge_index, edge_weight)\n",
    "        #h = h.relu()\n",
    "        h = self.fc1(h)\n",
    "        h = h.relu()\n",
    "        h = self.fc2(h)\n",
    "        h = h.relu()\n",
    "        h = self.fc3(h)\n",
    "        h = h.relu()\n",
    "        h = self.fc4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN()\n",
    "criterion2 = torch.nn.CrossEntropyLoss()\n",
    "criterion = FocalLoss(weight= 1. / torch.tensor([70, 463, 426, 2177, 631], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(big_data.x, big_data.edge_index, big_data.edge_attr)  # Perform a single forward pass.\n",
    "    loss = criterion2(out[big_data.train_mask], big_data.y[big_data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    experiment.log_metrics({\"loss\": loss}, epoch=epoch)\n",
    "    return loss, criterion2(out[big_data.train_mask], big_data.y[big_data.train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.544908___0.544908: 100%|███████████████████████████████████████████████████████████████████| 10000/10000 [04:15<00:00, 39.19it/s]\n"
     ]
    }
   ],
   "source": [
    "t = trange(10000, leave=True)\n",
    "\n",
    "with experiment.train():\n",
    "    for epoch in t:\n",
    "        loss, loss2 = train(epoch)\n",
    "        t.set_description(str(round(loss.item(), 6)) + \"___\" + str(round(loss2.item(), 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    out = model(big_data.x, big_data.edge_index, big_data.edge_attr)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred[big_data.test_mask] == big_data.y[big_data.test_mask]  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(big_data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814159292035399"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3767x5 and 10x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_correct \u001b[38;5;241m=\u001b[39m pred[data\u001b[38;5;241m.\u001b[39mtest_mask] \u001b[38;5;241m==\u001b[39m data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtest_mask]\n",
      "File \u001b[0;32m~/anaconda3/envs/msprime-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_weight):\n\u001b[0;32m---> 18\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#h = self.conv2(h, edge_index, edge_weight)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#h = h.relu()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/msprime-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/msprime-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:194\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m             edge_index \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m--> 194\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m    197\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight,\n\u001b[1;32m    198\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/msprime-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/msprime-env/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py:118\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m        x (Tensor): The features.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3767x5 and 10x10)"
     ]
    }
   ],
   "source": [
    "out = model(data.x, data.edge_index, data.edge_attr)\n",
    "pred = out.argmax(dim=1)\n",
    "test_correct = pred[data.test_mask] == data.y[data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "            'мордвины': 0,\n",
    "            'белорусы': 1,\n",
    "            'украинцы': 2,\n",
    "            'южные-русские': 3,\n",
    "            'северные-русские': 4,\n",
    "        }\n",
    "counts = {0: 70, 1: 463, 2: 426, 3: 2177, 4: 631}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23,   0,   0,   0,   2],\n",
       "       [  9,  82,  16,  21,   9],\n",
       "       [ 22,   7,  90,   4,   7],\n",
       "       [ 23,  55,  51, 486,  48],\n",
       "       [ 12,  12,   6,  19, 126]])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "sklearn.metrics.confusion_matrix(data.y[data.test_mask], pred[data.test_mask], labels=None, normalize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal loss\n",
    "\n",
    "```\n",
    "array([[ 23,   0,   0,   0,   2],\n",
    "       [  9,  87,  14,  18,   9],\n",
    "       [ 22,   9,  89,   2,   8],\n",
    "       [ 23,  59,  54, 479,  48],\n",
    "       [ 12,  12,   8,  17, 126]])\n",
    " ```\n",
    " \n",
    " CE loss\n",
    " \n",
    " ```\n",
    " array([[ 18,   0,   0,   5,   2],\n",
    "       [  0,  67,  10,  56,   4],\n",
    "       [  0,   4,  69,  50,   7],\n",
    "       [  1,  17,  16, 601,  28],\n",
    "       [  1,   7,   4,  46, 117]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([[0, 0, 0, 0, 0], \n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [1, 1, 1, 1, 1]])\n",
    "\n",
    "X = np.array([[1, 2, 3, 4],\n",
    "              [1, 2, 3, 4],\n",
    "              [1, 2, 3, 4],\n",
    "              [1, 2, 3, 4],\n",
    "              [1, 2, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0],\n",
       "       [ 5, 10, 15, 20]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(W1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([[1, 0, 0, 0, 0], \n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [1, 1, 1, 1, 1]])\n",
    "\n",
    "X = np.array([[1, 2, 3, 4],\n",
    "              [1, 2, 3, 4],\n",
    "              [1, 2, 3, 4],\n",
    "              [1, 2, 3, 4],\n",
    "              [1, 2, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(5, 16)\n",
      "  (conv2): GCNConv(16, 5)\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-17338e37a6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "m = GCN()\n",
    "print(m)\n",
    "\n",
    "out, h = m(data.x, data.edge_index, data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[0.1, 0.8, 0.1]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-5cb715fd771d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example of target with class indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2547)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "input = torch.tensor([[3.2, 1.3,0.2, 0.8], \n",
    "                     [3.2, 1.3,0.2, 0.8],\n",
    "                     [3.2, 1.3,0.2, 0.8]],dtype=torch.float)\n",
    "target = torch.tensor([0, 0, 0], dtype=torch.long)\n",
    "criterion(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7751, 0.1159, 0.0386, 0.0703],\n",
       "        [0.7751, 0.1159, 0.0386, 0.0703]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv(\"data/raw/CR_graph_rel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id1</th>\n",
       "      <th>node_id2</th>\n",
       "      <th>label_id1</th>\n",
       "      <th>label_id2</th>\n",
       "      <th>ibd_sum</th>\n",
       "      <th>ibd_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node_0</td>\n",
       "      <td>node_5</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>29.81720</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node_0</td>\n",
       "      <td>node_10</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>11.63220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node_0</td>\n",
       "      <td>node_11</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>23.90440</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node_0</td>\n",
       "      <td>node_18</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>11.25290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>node_0</td>\n",
       "      <td>node_20</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>мордвины</td>\n",
       "      <td>8.88252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67498</th>\n",
       "      <td>node_3741</td>\n",
       "      <td>node_3752</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>9.51327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67499</th>\n",
       "      <td>node_3745</td>\n",
       "      <td>node_3755</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>9.23221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67500</th>\n",
       "      <td>node_3749</td>\n",
       "      <td>node_3764</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>10.63310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67501</th>\n",
       "      <td>node_3754</td>\n",
       "      <td>node_3755</td>\n",
       "      <td>украинцы</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>8.04722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67502</th>\n",
       "      <td>node_3758</td>\n",
       "      <td>node_3766</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>белорусы</td>\n",
       "      <td>8.77936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        node_id1   node_id2 label_id1 label_id2   ibd_sum  ibd_n\n",
       "0         node_0     node_5  мордвины  мордвины  29.81720      4\n",
       "1         node_0    node_10  мордвины  мордвины  11.63220      1\n",
       "2         node_0    node_11  мордвины  мордвины  23.90440      2\n",
       "3         node_0    node_18  мордвины  мордвины  11.25290      1\n",
       "4         node_0    node_20  мордвины  мордвины   8.88252      1\n",
       "...          ...        ...       ...       ...       ...    ...\n",
       "67498  node_3741  node_3752  белорусы  белорусы   9.51327      1\n",
       "67499  node_3745  node_3755  белорусы  белорусы   9.23221      1\n",
       "67500  node_3749  node_3764  белорусы  белорусы  10.63310      1\n",
       "67501  node_3754  node_3755  украинцы  белорусы   8.04722      1\n",
       "67502  node_3758  node_3766  белорусы  белорусы   8.77936      1\n",
       "\n",
       "[67503 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [5]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67503it [00:13, 5057.07it/s]\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "            'мордвины': torch.tensor(0, dtype=torch.long),\n",
    "            'белорусы': torch.tensor(1, dtype=torch.long),\n",
    "            'украинцы': torch.tensor(2, dtype=torch.long),\n",
    "            'южные-русские': torch.tensor(3, dtype=torch.long),\n",
    "            'северные-русские': torch.tensor(4, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "\n",
    "y_labels = {}\n",
    "oho_labels = {}\n",
    "\n",
    "for index, row in tqdm(data_csv.iterrows()):\n",
    "    node1 = row[\"node_id1\"]\n",
    "    node2 = row[\"node_id2\"]\n",
    "    label1 = row[\"label_id1\"]\n",
    "    label2 = row[\"label_id2\"]\n",
    "    ibd_sum = row[\"ibd_sum\"]\n",
    "\n",
    "    id1 = int(node1[5:])\n",
    "    id2 = int(node2[5:])\n",
    "\n",
    "    edge_index.append(torch.tensor([id1, id2], dtype=torch.long))\n",
    "    edge_attr.append(torch.tensor([ibd_sum], dtype=torch.float))\n",
    "\n",
    "    if id1 not in oho_labels:\n",
    "        y_labels[id1] = d[label1]\n",
    "    if id2 not in oho_labels:\n",
    "        y_labels[id2] = d[label2]\n",
    "\n",
    "y_labels = dict(sorted(y_labels.items()))\n",
    "y = torch.stack(list(y_labels.values()))\n",
    "\n",
    "edge_attr = torch.stack(edge_attr).contiguous()\n",
    "edge_index = torch.stack(edge_index).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "counts = defaultdict(int)\n",
    "\n",
    "for l in y_labels:\n",
    "    counts[y_labels[l].item()] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {0: 70, 1: 463, 2: 426, 3: 2177, 4: 631})"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ibd_sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4410\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-bfc1b671f2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mibd_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ibd_sum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4417\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4418\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4419\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4420\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4421\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ibd_sum'"
     ]
    }
   ],
   "source": [
    "ibd_sum = row[\"ibd_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67503it [00:04, 14309.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(int)\n",
    "ibd_s = defaultdict(list)\n",
    "connections = np.zeros([3767, 6], dtype=int)\n",
    "\n",
    "nations = {\n",
    "            'мордвины': 0,\n",
    "            'белорусы': 1,\n",
    "            'украинцы': 2,\n",
    "            'южные-русские': 3,\n",
    "            'северные-русские': 4,\n",
    "        }\n",
    "\n",
    "for index, row in tqdm(data_csv.iterrows()):\n",
    "    node1 = row[\"node_id1\"]\n",
    "    node2 = row[\"node_id2\"]\n",
    "    label1 = row[\"label_id1\"]\n",
    "    label2 = row[\"label_id2\"]\n",
    "    ibd_sum = row[\"ibd_sum\"]    \n",
    "    \n",
    "    ibd_ = []\n",
    "    \n",
    "    key = label1 + \"_\" + label2\n",
    "    reverse_key = label2 + \"_\" + label1\n",
    "    \n",
    "    if reverse_key in d:\n",
    "        d[reverse_key] += 1\n",
    "        ibd_s[reverse_key].append(ibd_sum)\n",
    "    else:\n",
    "        d[key] += 1\n",
    "        ibd_s[key].append(ibd_sum)\n",
    "    \n",
    "    id1 = int(node1[5:])\n",
    "    id2 = int(node2[5:])\n",
    "    \n",
    "    connections[id1][nations[label2]+1] += ibd_sum\n",
    "    connections[id2][nations[label1]+1] += ibd_sum\n",
    "    connections[id1][0] = nations[label1]\n",
    "    connections[id2][0] = nations[label2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мордвины_мордвины 20.73 20.28\n",
      "мордвины_южные-русские 9.88 2.59\n",
      "мордвины_северные-русские 10.91 4.22\n",
      "мордвины_белорусы 9.56 1.95\n",
      "мордвины_украинцы 9.54 1.63\n",
      "белорусы_северные-русские 9.91 2.47\n",
      "белорусы_южные-русские 9.99 2.57\n",
      "белорусы_белорусы 27.42 235.24\n",
      "белорусы_украинцы 10.1 8.05\n",
      "украинцы_южные-русские 9.93 2.62\n",
      "украинцы_северные-русские 9.89 2.28\n",
      "украинцы_украинцы 36.6 274.93\n",
      "южные-русские_южные-русские 14.5 104.91\n",
      "южные-русские_северные-русские 9.96 2.54\n",
      "северные-русские_северные-русские 12.52 72.48\n"
     ]
    }
   ],
   "source": [
    "for key in ibd_s:\n",
    "    print(key, round(np.mean(ibd_s[key]), 2), round(np.std(ibd_s[key]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'мордвины_мордвины': 268,\n",
       "             'мордвины_южные-русские': 394,\n",
       "             'мордвины_северные-русские': 256,\n",
       "             'мордвины_белорусы': 42,\n",
       "             'мордвины_украинцы': 38,\n",
       "             'белорусы_северные-русские': 1851,\n",
       "             'белорусы_южные-русские': 7144,\n",
       "             'белорусы_белорусы': 1759,\n",
       "             'белорусы_украинцы': 1085,\n",
       "             'украинцы_южные-русские': 4902,\n",
       "             'украинцы_северные-русские': 1137,\n",
       "             'украинцы_украинцы': 1231,\n",
       "             'южные-русские_южные-русские': 33241,\n",
       "             'южные-русские_северные-русские': 10225,\n",
       "             'северные-русские_северные-русские': 3930})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_nation_connections = defaultdict(list)\n",
    "for i in range(len(connections)):\n",
    "    person_nation_connections[connections[i][0]].append(connections[i][1:])\n",
    "\n",
    "person_nation_connections_mean = {}\n",
    "for key in person_nation_connections: \n",
    "    person_nation_connections_mean[key] = np.mean(np.array(person_nation_connections[key]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([154.97142857,   5.47142857,   4.97142857,  53.1       ,\n",
       "         38.24285714]),\n",
       " 1: array([  0.82721382, 204.825054  ,  22.64146868, 147.30669546,\n",
       "         37.81857451]),\n",
       " 2: array([  0.81690141,  24.60798122, 208.88262911, 109.11502347,\n",
       "         25.21596244]),\n",
       " 3: array([  1.7073955 ,  31.32889297,  21.35186036, 428.99954065,\n",
       "         44.69637115]),\n",
       " 4: array([  4.24247227,  27.7496038 ,  17.02377179, 154.20602219,\n",
       "        150.18700475])}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_nation_connections_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 2, 3]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([3767, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
